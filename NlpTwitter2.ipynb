{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74fb2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd Approach with Tensorflow libary\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451fb24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Sentiment.csv\")\n",
    "#keeping only text and sentiment columns\n",
    "data = data[['text','sentiment','candidate']]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2229e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data.text.values\n",
    "tokenizer = Tokenizer(num_words = 10000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "encoded_docs = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen = 200)\n",
    "sentiment_lable = data.sentiment.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75f44cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 200, 64)           640000    \n",
      "                                                                 \n",
      " spatial_dropout1d_9 (Spatia  (None, 200, 64)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 20)                6800      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 646,821\n",
      "Trainable params: 646,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, SpatialDropout1D, Embedding\n",
    "embedding_vector_length = 64\n",
    "vocab_size = 10000\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length, input_length = 200))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(20, dropout = 0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2894041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "174/174 [==============================] - 66s 344ms/step - loss: -1.7499 - accuracy: 0.1593 - val_loss: -4.5168 - val_accuracy: 0.1686\n",
      "Epoch 2/2\n",
      "174/174 [==============================] - 59s 341ms/step - loss: -4.0979 - accuracy: 0.1593 - val_loss: -6.4892 - val_accuracy: 0.1686\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded_sequence, sentiment_lable[0], validation_split=0.2, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f04f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    tw = tokenizer.texts_to_sequences([text])\n",
    "    tw = pad_sequences(tw,maxlen=200)\n",
    "    prediction = int(model.predict(tw).round().item())\n",
    "    print(\"Predicted Label : \",sentiment_lable[1][prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc6b59d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 545ms/step\n",
      "Predicted Label :  Positive\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicted Label :  Positive\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Predicted Label :  Positive\n"
     ]
    }
   ],
   "source": [
    "example1 = [\"RT @DanScavino: #GOPDebate @realDonaldTrump delivered the highest ratings in the history of presidential debates\"]\n",
    "example2 = [\"RT @NancyOsborne180: Last night's debate proved it! #GOPDebate #BATsAsk @BadassTeachersA #TBATs\"]\n",
    "example3 = [\"Going on #MSNBC Live with @ThomasARoberts around 2 PM ET.  #GOPDebate\"]\n",
    "predict_sentiment(example1)\n",
    "predict_sentiment(example2)\n",
    "predict_sentiment(example3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330e121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
